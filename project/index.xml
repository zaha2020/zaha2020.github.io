<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Zahra Habibzadeh</title>
    <link>https://zaha2020.github.io/project/</link>
      <atom:link href="https://zaha2020.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zaha2020.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://zaha2020.github.io/project/</link>
    </image>
    
    <item>
      <title>Development of L-System Grammer</title>
      <link>https://zaha2020.github.io/project/development_l-system_grammer/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/development_l-system_grammer/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we implemented L_System in two parts. In the first part, we added the color feature to this system by implementing the code, and in the next part, we explained the rules of growth in 3D and color in Houdini software.&lt;/p&gt;
&lt;p&gt;The following book was used for further study with the following title by Przemyslaw Prusinkiewicz and Aristid Lindenmayer:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;The Algorithmic Beauty of Plants&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;By generating different rules and including color in the rules, we drew plant species (trees) in different states because the generation is set randomly. In general, we showed in two random modes and in the third generation and the fourth generation to understand the difference in the number of repetitions in pattern generation in this system.&lt;/p&gt;
&lt;p&gt;By using the definition of different rules in the Houdini software, we put all the species together to have a forest of seven types of species.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bio-Inspired Optimization methods</title>
      <link>https://zaha2020.github.io/project/optimization_inspired_by_nature/</link>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/optimization_inspired_by_nature/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we  solved some standard and common optimization problems that are used to compare optimization algorithms using the algorithms of Artificial Bee Colony, Firefly and Particle Swarm Optimization and compared their efficiency.&lt;/p&gt;
&lt;p&gt;The optimization problems used in this project is related to an article with the following title by Xin-She Yang:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Test Problems in Optimization&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;In terms of optimality, we compare each function in 3 algorithms with *f found in the article
According to the results of the tables for each test function in the 3 algorithms, we can see that in all the functions, the optimization has occurred in the 3 algorithms, but in general, the Artificial Bee Colony algorithm has worked more accurately and was able to be closer to the optimal point in get the article.&lt;/p&gt;
&lt;p&gt;One of the characteristics of these 3 algorithms is the high convergence speed, but if we draw the following graphs for each function, we can see that in all the test functions, the Artificial Bee Colony algorithm is faster than the other two algorithms for this category of optimization problems. Convergence has been reached, which means that the speed of convergence in this algorithm is high, and the two algorithms of Particle Swarm and Firefly are sometimes trapped in the local optimum.&lt;/p&gt;
&lt;p&gt;The Firefly algorithm has solved all the test functions with the shortest possible time compared to the other 2 algorithms, and the Artificial Bee Colony algorithm has the longest execution time with about 1 minute and 9 seconds.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The effect of the combination of economic and social analysis on the prediction of stock price fluctuations</title>
      <link>https://zaha2020.github.io/project/stock_prediction/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/stock_prediction/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In the first phase, a general study was conducted on technical analysis, types of candles and types of indicators, etc., in various sources, including the introduced Telegram address. In the second phase, social data was received from the hashtag site in the form of two Excel files and a Hashtag site for every 10 symbols, which Hashtag file was used for the graphic analysis of Telegram channels for 10 symbols, which can be seen in the second phase of the project. Next, in the third phase, economic and financial data were downloaded by Docker from &lt;a href=&#34;https://www.tsetmc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tsetms Pages&lt;/a&gt;, then after several stages of coding for editing, the important columns of this data, along with the obtained indicators, were received for all 10 symbols and are transferred to the fourth phase.&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result:&lt;/h2&gt;
&lt;p&gt;In the last phase and the fourth phase, we will have two types of predictions using recurrent neural networks, in the first prediction, we predict the stock market price from the tables of the third phase, and in the second prediction, from the combination of the indicators of the tables of the second phase and Third, we use it to predict the price. In fact, we enter social data into the prediction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning for Cartpole Environment</title>
      <link>https://zaha2020.github.io/project/deep_rl/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/deep_rl/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription&lt;/h2&gt;
&lt;p&gt;In this project, we implement a policy gradient method using deep neural networks to train our agent in &lt;code&gt;cartpole&lt;/code&gt; environment from the gym. For this implementation, we&amp;rsquo;ve used the Tensorflow framework.&lt;/p&gt;
&lt;h2 id=&#34;environment&#34;&gt;Environment&lt;/h2&gt;
&lt;p&gt;In &lt;code&gt;cartpole&lt;/code&gt; Environment, our agent just has two actions to do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;+1: push cart to the right&lt;/li&gt;
&lt;li&gt;0: push cart to the left
our goal is to keep the balance of this cart.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;p&gt;We train our agent for 1000 episodes&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generating music using LSTMs</title>
      <link>https://zaha2020.github.io/project/music_generation/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/music_generation/</guid>
      <description>&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve used &lt;code&gt;MIDI Music Class&lt;/code&gt; for generating music using LSTMs. from various artists, we&amp;rsquo;ve chosen melodies from Chopin Frédéric and Mozart.
several preprocessing steps have been done on the data before training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removing rare notes&lt;/li&gt;
&lt;li&gt;Creating a corpus of notes&lt;/li&gt;
&lt;li&gt;Generating sequences&lt;/li&gt;
&lt;li&gt;Considering the note after the end of the sequence as a label&lt;/li&gt;
&lt;li&gt;One-hot encoding for labels&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;train&#34;&gt;Train&lt;/h2&gt;
&lt;p&gt;After doing preprocessing steps, We&amp;rsquo;ve used LSTMs to generate Music. For this purpose, we generate notes and after that, we convert these generated notes to music with the help of the &lt;code&gt;music21&lt;/code&gt; python library.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An analysis of Telegram channels related to the dollar and its price</title>
      <link>https://zaha2020.github.io/project/social_networks/</link>
      <pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/social_networks/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, various analyzes such as graph topology, distribution of the number of content, and a number of visits to channels were performed using the NetworkX library. as well as the top 10 nodes of various criteria such as betweenness, efficiency, page rank, etc., using Gephi software and tools was found and finally, the cause of superiority was investigated.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Classifying images using Convolutional Neural Networks</title>
      <link>https://zaha2020.github.io/project/cnn/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/cnn/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, We investigate several configurations of CNNs to classify input images.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;For this task, we&amp;rsquo;ve used &lt;a href=&#34;https://github.com/zalandoresearch/fashion-mnist&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;Fashion MNSIT&lt;/code&gt;&lt;/a&gt; which contains 10 classes of data for a classification task.&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve trained Network with several Configurations to find the best setting for our task. We have checked for these settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MLP with a different number of hidden layers&lt;/li&gt;
&lt;li&gt;MLP with different Activation functions&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks with DropOut&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks with DropOut and Batch normalization&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Accuracy for different settings mentioned above are in  the below table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Accuracy%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CNN + fully connected&lt;/td&gt;
&lt;td&gt;90,63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN + fully connected + Pooling + Batch normalization&lt;/td&gt;
&lt;td&gt;90,17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN + fully connected + Pooling + CNN_Dropout(0.3,0.3,0.5)&lt;/td&gt;
&lt;td&gt;90,56&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN + fully connected + Pooling + CNN_Dropout(0.2,0.2,0.2)&lt;/td&gt;
&lt;td&gt;90,89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN + fully connected + Pooling + Batchnormalization + CNN_Dropout(0.2,0.2,0.2)&lt;/td&gt;
&lt;td&gt;91,04&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>A real time BigData system for analysis of online Persian Twitter data</title>
      <link>https://zaha2020.github.io/project/realtime_system/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/realtime_system/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;This Project is a group work with &lt;a href=&#34;https://github.com/arminayat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Armin Ayatollahi&lt;/a&gt;, &lt;a href=&#34;https://github.com/yaramohamadi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yara M. Bahram
&lt;/a&gt;, &lt;a href=&#34;https://github.com/mohammad-nili&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mohammad-nili&lt;/a&gt;. in this project we used online Persian Twitter data for Designing a real-time system.
For analyzing the content of Persian tweets, we developed a complete data processing line, starting with collecting data and sending it to Elastic Search, processing and storing hashtag/channel history in Cassandra, saving real-time statistics in Redis, and statistical analysis of data to The help of Superset/Clickhouse was formed and the centrality of data transfer was with Kafka.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing a real dataset with R programming language</title>
      <link>https://zaha2020.github.io/project/statistical_inference/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/statistical_inference/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we intended to study and analyze a series of the real dataset. To begin analyzing a dataset, the first step was to get familiar with it. In the first step, this acquaintance can be made by observing the features of the dataset and distribution of the values and visualizing the data to make initial guesses about it. In the next step, by performing statistical tests, we made sure our guesses are correct and made our claims with certainty.&lt;/p&gt;
&lt;h2 id=&#34;datasets-description&#34;&gt;Datasets Description:&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dataset name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Students_Performance&lt;/td&gt;
&lt;td&gt;This dataset includes information about a sample of students studying in two different institutes as well as their grades in three different exams.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Using Apache Spark for NLP, Log mining, Stock and Graph tasks</title>
      <link>https://zaha2020.github.io/project/spark/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/spark/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we&amp;rsquo;ve used Apache Spark for NLP, Log mining, and Stock and Graph tasks.&lt;/p&gt;
&lt;h2 id=&#34;spark-for-nlp&#34;&gt;Spark for NLP&lt;/h2&gt;
&lt;p&gt;For this task, we first counted and displayed the number of words in the txt.Input file. We also reported how often each word was repeated and saved the output to a .txt file. In this step, all punctuation marks (exclamation marks, question marks, periods, etc.) were removed. Finally, we created the &lt;code&gt;bigram&lt;/code&gt; of the prepared data frame and compute the count of each bigram.&lt;/p&gt;
&lt;h2 id=&#34;logfile-mining-with-spark&#34;&gt;LogFile Mining with Spark&lt;/h2&gt;
&lt;p&gt;The log file of this exercise is called Log, which is related to HTTP requests. This file was explored using the basic commands of Spark, SQL Spark, or Dataframes Spark.&lt;/p&gt;
&lt;h2 id=&#34;stock-market-analysis-using-spark&#34;&gt;Stock Market Analysis using Spark&lt;/h2&gt;
&lt;p&gt;In this task, the 6-month stock market data of the Iran Stock Exchange was used. We downloaded daily stock market data for a two-month period that can have at least thirty distinct days. First, with the help of Spark, we opened the files and added the day, month, and year columns to them. (a date column).
In this task, the questions were answered with Spark and with two different approaches (Dataframe Spark / SQL Spark).&lt;/p&gt;
&lt;h2 id=&#34;spark-graphx&#34;&gt;Spark GraphX&lt;/h2&gt;
&lt;p&gt;The graphs in question are extracted from &lt;a href=&#34;https://www.wikipedia.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia&lt;/a&gt; articles in this task. Each node is a Wikipedia article and an edge from article A to article B indicates that article A referred to article B.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Parkinson disease using signals of speech data with ensemble learning</title>
      <link>https://zaha2020.github.io/project/parkinson/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/parkinson/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;This Project is a group work with &lt;a href=&#34;https://github.com/amirhosein-mesbah&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amirhossein Mesbah&lt;/a&gt;. in this project we used signals of speech data for a binary classification task to check if the person to whom the sound belongs has Parkinson&amp;rsquo;s disease or not.&lt;/p&gt;
&lt;p&gt;The data used in this project is related to an article with the following title by Jefferson S.Almeida et al:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Detecting Parkinson’s disease with sustained phonation and speech signals using
machine learning techniques&amp;rdquo;&lt;/p&gt;
&lt;p&gt;We implemented the methods used in this paper for data preprocessing, dimensionality reduction and model training. Also, in addition to these cases, we also used ensemble models for training and better performance.&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result:&lt;/h2&gt;
&lt;p&gt;The best performance was related to the ensemble model using KNN algorithm, whose accuracy was equal to 96,10%. The results of the rest of the models are available in the table below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Algorithms&lt;/th&gt;
&lt;th&gt;Accuracy%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Logistic regression&lt;/td&gt;
&lt;td&gt;87,23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SVM&lt;/td&gt;
&lt;td&gt;93,97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;84,04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;KNN(K=1)&lt;/td&gt;
&lt;td&gt;94,33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MLP&lt;/td&gt;
&lt;td&gt;91,84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBF&lt;/td&gt;
&lt;td&gt;93,26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ensemble&lt;/td&gt;
&lt;td&gt;96,10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Investigating the main reason for sales decline in a wood industry factory</title>
      <link>https://zaha2020.github.io/project/discriminative_project/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/discriminative_project/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In order to find the main reason for the decrease in sales, first, the 10-year sales of the factory were checked to determine the rate of decrease in sales, then the information was collected randomly from 105 customers in the form of a survey. Next, important features were extracted from the survey sheets and the final table was made.&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;In the following, the level of satisfaction of the customers from different departments of the factory, which was asked in the survey, was checked in order to check which department the customers have the least level of satisfaction with.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

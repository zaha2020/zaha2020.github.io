<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Zahra Habibzadeh</title>
    <link>https://zaha2020.github.io/project/</link>
      <atom:link href="https://zaha2020.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zaha2020.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://zaha2020.github.io/project/</link>
    </image>
    
    <item>
      <title>Development of L-System Grammer</title>
      <link>https://zaha2020.github.io/project/development_l-system_grammer/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/development_l-system_grammer/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we implemented L_System in two parts. In the first part, we added the color feature to this system by implementing the code, and in the next part, we explained the rules of growth in 3D and color in Houdini software.&lt;/p&gt;
&lt;p&gt;The following book was used for further study with the following title by Przemyslaw Prusinkiewicz and Aristid Lindenmayer:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;The Algorithmic Beauty of Plants&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;By generating different rules and including color in the rules, we drew plant species (trees) in different states because the generation is set randomly. In general, we showed in two random modes and in the third generation and the fourth generation to understand the difference in the number of repetitions in pattern generation in this system.&lt;/p&gt;
&lt;p&gt;By using the definition of different rules in the Houdini software, we put all the species together to have a forest of seven types of species.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimization inspired by nature</title>
      <link>https://zaha2020.github.io/project/optimization_inspired_by_nature/</link>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/optimization_inspired_by_nature/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, we  solved some standard and common optimization problems that are used to compare optimization algorithms using the algorithms of Artificial Bee Colony, Firefly and Particle Swarm Optimization and compared their efficiency.&lt;/p&gt;
&lt;p&gt;The optimization problems used in this project is related to an article with the following title by Xin-She Yang:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Test Problems in Optimization&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;In terms of optimality, we compare each function in 3 algorithms with *f found in the article
According to the results of the tables for each test function in the 3 algorithms, we can see that in all the functions, the optimization has occurred in the 3 algorithms, but in general, the Artificial Bee Colony algorithm has worked more accurately and was able to be closer to the optimal point in get the article&lt;/p&gt;
&lt;p&gt;One of the characteristics of these 3 algorithms is the high convergence speed, but if we draw the following graphs for each function, we can see that in all the test functions, the Artificial Bee Colony algorithm is faster than the other two algorithms for this category of optimization problems. Convergence has been reached, which means that the speed of convergence in this algorithm is high, and the two algorithms of Particle Swarm and Firefly are sometimes trapped in the local optimum.&lt;/p&gt;
&lt;p&gt;The Firefly algorithm has solved all the test functions with the shortest possible time compared to the other 2 algorithms, and the Artificial Bee Colony algorithm has the longest execution time with about 1 minute and 9 seconds.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The effect of the combination of economic and social analysis on the prediction of stock price fluctuations</title>
      <link>https://zaha2020.github.io/project/stock_prediction/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/stock_prediction/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In the first phase, a general study was conducted on technical analysis, types of candles and types of indicators, etc., in various sources, including the introduced Telegram address. In the second phase, social data was received from the hashtag site in the form of two Excel files and Hashtag site for each 10 symbols, which Hashtag file was used for graphic analysis of Telegram channels for 10 symbols, which can be seen in the second phase of the project. Next, in the third phase, economic and financial data were downloaded by Docker from tsetms Pages, then after several stages of coding for editing, the important columns of this data, along with the obtained indicators, were received for all 10 symbols and are transferred to the fourth phase. in the last phase and the fourth phase, we will have two types of predictions using recurrent neural networks, in the first prediction, we predict the stock market price from the tables of the third phase, and in the second prediction, from the combination of the indicators of the tables of the second phase and Third, we use it to predict the price. In fact, we enter social data into the prediction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An analysis of Telegram channels related to the dollar and its price</title>
      <link>https://zaha2020.github.io/project/social_networks/</link>
      <pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/social_networks/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In this project, various analyzes such as graph topology, distribution of the number of content, number of visits to channels were performed using the NetworkX library. as well as the top 10 nodes of various criteria such as betweenness, efficiency, page rank, etc., using Gephi software and tools was found and finally the cause of superiority was investigated.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Parkinson disease using signals of speech data with ensemble learning</title>
      <link>https://zaha2020.github.io/project/parkinson/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/parkinson/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;This Project is a group work with &lt;a href=&#34;https://github.com/amirhosein-mesbah&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amirhossein Mesbah&lt;/a&gt;. in this project we used signals of speech data for a binary classification task to check if the person to whom the sound belongs has Parkinson&amp;rsquo;s disease or not.&lt;/p&gt;
&lt;p&gt;The data used in this project is related to an article with the following title by Jefferson S.Almeida et al:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Detecting Parkinsonâ€™s disease with sustained phonation and speech signals using
machine learning techniques&amp;rdquo;&lt;/p&gt;
&lt;p&gt;We implemented the methods used in this paper for data preprocessing, dimensionality reduction and model training. Also, in addition to these cases, we also used ensemble models for training and better performance.&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result:&lt;/h2&gt;
&lt;p&gt;The best performance was related to the ensemble model using KNN algorithm, whose accuracy was equal to 96,10%. The results of the rest of the models are available in the table below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Algorithms&lt;/th&gt;
&lt;th&gt;Accuracy%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Logistic regression&lt;/td&gt;
&lt;td&gt;87,23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SVM&lt;/td&gt;
&lt;td&gt;93,97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;84,04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;KNN(K=1)&lt;/td&gt;
&lt;td&gt;94,33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MLP&lt;/td&gt;
&lt;td&gt;91,84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBF&lt;/td&gt;
&lt;td&gt;93,26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ensemble&lt;/td&gt;
&lt;td&gt;96,10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Investigating the main reason for sales decline in a wood industry factory</title>
      <link>https://zaha2020.github.io/project/discriminative_project/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/discriminative_project/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;In order to find the main reason for the decrease in sales, first the 10-year sales of the factory were checked to determine the rate of decrease in sales, then information was collected randomly from 105 customers in the form of a survey. Next, important features were extracted from the survey sheets and the final table was made.&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;In the following, the level of satisfaction of the customers from different departments of the factory, which was asked in the survey, was checked in order to check which department the customers have the least level of satisfaction with.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A real time BigData system for analysis of online Persian Twitter data</title>
      <link>https://zaha2020.github.io/project/realtime_system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://zaha2020.github.io/project/realtime_system/</guid>
      <description>&lt;h2 id=&#34;decription&#34;&gt;Decription:&lt;/h2&gt;
&lt;p&gt;This Project is a group work with &lt;a href=&#34;https://github.com/arminayat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Armin Ayatollahi&lt;/a&gt;, &lt;a href=&#34;https://github.com/yaramohamadi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yara M. Bahram
&lt;/a&gt;, &lt;a href=&#34;https://github.com/mohammad-nili&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mohammad-nili&lt;/a&gt;. in this project we used online Persian Twitter data for Designing a real-time system.
For analyzing the content of Persian tweets, we developed a complete data processing line, starting with collecting data and sending it to Elastic Search, processing and storing hashtag/channel history in Cassandra, saving real-time statistics in Redis, and statistical analysis of data to The help of Superset/Clickhouse was formed and the centrality of data transfer was with Kafka.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
